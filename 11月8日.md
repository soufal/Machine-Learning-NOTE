## 11月8日打卡：

作业1：该卡片朴素贝叶斯分类算法的原理，为什么称之为“朴素”？

**朴素贝叶斯法**是基于贝叶斯定理与特征条件独立假设的分类方法。

对于给定的数据集：

* 基于特征条件独立假设学习输入/输出的联合概率分布；
* 基于此模型，对给定的输入x，利用贝叶斯定理求出**后验概率最大**的输出y。    

为了学习到联合概率分布：

* 先学习先验概率分布：

  $$P(Y=c_k), k=1,2,...,K$$

* 学习条件概率分布：

  $$P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},...,X^{(n)}=x^{(n)}|Y=c_k), k = 1,2,...,K$$

* 最后学习到联合概率分布$P(X,Y)$.     

*朴素贝叶斯法对条件概率作了条件独立性的假设。这是一个较强的假设，朴素贝叶斯也由此得名。*     

条件独立性假设是：

$$P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},...,X^{(n)}=x^{(n)}|Y=c_k)=\prod_{j=1}^{n}P(X^{(j)}=x^{(j)}|Y=c_k)$$

他实际上学习到生成数据的机制，所以属于**生成模型**。条件独立假设等于是说用于分类的特征在类确定的条件下都是条件独立的。

* 后验概率可以根据贝叶斯定理进行：

  $$P(Y=c_k|X=x)=\frac{P(X=x|Y=c_k)P(Y=c_k)}{\sum_kP(X=x|Y=c_k)P(Y=c_k)}$$

* 朴素贝叶斯分类器可以表示为：

  $$y=f(x)=argmax_{c_k}\frac{P(Y=c_k)\prod_jP(X^{(j)}=x^{(j)}|Y=c_k)}{\sum_kP(Y=c_k)\prod_jP(X^{(j)}=x^{(j)}|Y=c_k)}$$

  由于在上式中，分母对于所有的$c_k$都是相同的，所以：

  $$y=f(x)=argmax_{c_k}P(Y=c_k)\prod_jP(X^{(j)}=x^{(j)}|Y=c_k)$$

